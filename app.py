import pandas as pd
import numpy as np
import streamlit as st
import os

# --- Imports cho c√°c m√¥ h√¨nh Scikit-learn ---
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

# --- Imports cho c√°c m√¥ h√¨nh b√™n ngo√†i (C·∫¶N PH·∫¢I C√ÄI ƒê·∫∂T B·∫∞NG PIP) ---
try:
    import xgboost as xgb
    XGBRegressor = xgb.XGBRegressor
except ImportError:
    XGBRegressor = None
    
try:
    import lightgbm as lgb
    LGBMRegressor = lgb.LGBMRegressor
except ImportError:
    LGBMRegressor = None

try:
    import catboost as cat
    CatBoostRegressor = cat.CatBoostRegressor
except ImportError:
    CatBoostRegressor = None

# -----------------------------------------------------------------------------------
# THAM S·ªê C·∫§U H√åNH V√Ä T√äN FILE
# -----------------------------------------------------------------------------------
RAW_DATA_FILE = "Data_tho_chua_xu_ly.csv"
TARGET_COL = 'RON 95-III(VND)'
TEST_SIZE = 150 
LAG_W = [1, 7] 
VOL_W = 7      
EVENT_LAG = [3, 7] 

EVENT_MAP = {
    'Cung (OPEC & S·∫£n l∆∞·ª£ng)': 'event_Cung (OPEC & S·∫£n l∆∞·ª£ng)',
    'Cung (T·ªìn kho M·ªπ)': 'event_Cung (T·ªìn kho M·ªπ)',
    'C·∫ßu (Kinh t·∫ø vƒ© m√¥)': 'event_C·∫ßu (Kinh t·∫ø vƒ© m√¥)',
    'S·ª± c·ªë & Gi√°n ƒëo·∫°n': 'event_S·ª± c·ªë & Gi√°n ƒëo·∫°n',
    'ƒê·ªãa ch√≠nh tr·ªã & Xung ƒë·ªôt': 'event_ƒê·ªãa ch√≠nh tr·ªã & Xung ƒë·ªôt',
    'ƒê·ªìng USD & T√†i ch√≠nh': 'event_ƒê·ªìng USD & T√†i ch√≠nh'
}

# -----------------------------------------------------------------------------------
# H√ÄM FEATURE ENGINEERING V√Ä SCALING (Gi·ªØ nguy√™n)
# -----------------------------------------------------------------------------------
def create_features(df_raw, scaler=None, fit_scaler=False):
    """Th·ª±c hi·ªán to√†n b·ªô qu√° tr√¨nh Feature Engineering v√† Scaling/Transforming."""
    df = df_raw.copy()
    
    # 1. Basic Cleaning
    df['date'] = pd.to_datetime(df['date'])
    df = df.set_index('date').sort_index()

    cols_to_fill = ['Gia_Brent(USD)', 'Gia_WTI(USD)', 'USD/VND', 'Bien_loi_nhuan']
    df[cols_to_fill] = df[cols_to_fill].ffill().bfill()
    
    df = df.drop(columns=['E5 RON 92-II(VND)', 'Bien_loi_nhuan']) 

    # 2. Time Series Features
    price_cols = ['Gia_Brent(USD)', 'Gia_WTI(USD)', 'USD/VND']
    
    for col in price_cols:
        col_name_base = col.split("(")[0]
        for lag in LAG_W:
            df[f'{col_name_base}_lag{lag}'] = df[col].shift(lag)
        
        df[f'{col_name_base}_pct'] = df[col].pct_change()
        df[f'{col_name_base}_vol{VOL_W}'] = df[col].rolling(window=VOL_W).std()
        
    df = df.dropna()

    # 3. Event Features
    df['loai_su_kien'] = df['loai_su_kien'].fillna('No_Event')
    df['tang_giam'] = df['tang_giam'].fillna('None')

    event_dummies = pd.get_dummies(df['loai_su_kien']).astype(int)
    event_dummies = event_dummies.rename(columns={k: v for k, v in zip(EVENT_MAP.keys(), EVENT_MAP.values()) if k in event_dummies.columns})
    
    for col in EVENT_MAP.values():
        if col not in event_dummies.columns:
            event_dummies[col] = 0
            
    if 'No_Event' in event_dummies.columns:
        event_dummies = event_dummies.drop(columns=['No_Event'])
    
    df['event_impact'] = (df['loai_su_kien'] != 'No_Event').astype(int)

    sentiment_map = {'Gi·∫£m': -1, 'TƒÉng': 1, 'None': 0}
    df['sentiment_score'] = df['tang_giam'].map(sentiment_map)
    df['event_sentiment_7'] = df['sentiment_score'].rolling(window=VOL_W).sum()
    df = df.drop(columns=['sentiment_score']) 

    for lag in EVENT_LAG:
        df[f'event_lag_{lag}'] = df['event_impact'].shift(1).rolling(window=lag).sum()

    df = pd.concat([df.drop(columns=['loai_su_kien', 'tang_giam', 'ten_su_kien']), event_dummies], axis=1).dropna()
    
    y_raw = df[TARGET_COL]
    X_features = df.drop(columns=[TARGET_COL])
    
    # 4. Scaling (Standard Scaling)
    if fit_scaler:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_features)
        X_scaled_df = pd.DataFrame(X_scaled, index=X_features.index, columns=X_features.columns)
        return X_scaled_df, y_raw, scaler
    
    elif scaler is not None:
        X_scaled = scaler.transform(X_features)
        X_scaled_df = pd.DataFrame(X_scaled, index=X_features.index, columns=X_features.columns)
        return X_scaled_df, y_raw

    return X_features, y_raw 

# -----------------------------------------------------------------------------------
# H√ÄM T·∫¢I V√Ä HU·∫§N LUY·ªÜN NHI·ªÄU M√î H√åNH (ƒê√É C·∫¨P NH·∫¨T)
# -----------------------------------------------------------------------------------
@st.cache_resource
def load_and_train_model():
    """T·∫£i d·ªØ li·ªáu, chu·∫©n b·ªã, v√† hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh."""
    if not os.path.exists(RAW_DATA_FILE):
        st.error(f"File dataset '{RAW_DATA_FILE}' kh√¥ng t√¨m th·∫•y.")
        return None, None, None, None, None

    df_raw = pd.read_csv(RAW_DATA_FILE)

    X_scaled, y_raw, scaler = create_features(df_raw, fit_scaler=True)
    
    X_train = X_scaled.iloc[:-TEST_SIZE]
    X_test = X_scaled.iloc[-TEST_SIZE:]
    y_train = y_raw.iloc[:-TEST_SIZE]
    y_test = y_raw.iloc[-TEST_SIZE:]

    # ƒê·ªãnh nghƒ©a c√°c m√¥ h√¨nh
    models = {
        "Random Forest Regressor": RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1),
        "Gradient Boosting Regressor": GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),
        "Linear Regression": LinearRegression(),
        "Ridge Regression": Ridge(alpha=1.0, random_state=42),
    }
    
    # Th√™m c√°c m√¥ h√¨nh b√™n ngo√†i n·∫øu ƒë√£ c√†i ƒë·∫∑t
    if XGBRegressor is not None:
        models["XGBoost Regressor"] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    if LGBMRegressor is not None:
        # T·∫Øt verbose cho LightGBM
        models["LightGBM Regressor"] = LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1)
    if CatBoostRegressor is not None:
        # T·∫Øt hi·ªÉn th·ªã ti·∫øn tr√¨nh cho CatBoost
        models["CatBoost Regressor"] = CatBoostRegressor(iterations=100, random_state=42, verbose=0)


    # Hu·∫•n luy·ªán m√¥ h√¨nh v√† l∆∞u RMSE
    model_results = {}
    for name, model in models.items():
        try:
            model.fit(X_train, y_train.values)
            y_pred_test = model.predict(X_test)
            rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
            model_results[name] = {'model': model, 'rmse': rmse}
        except Exception as e:
            # B·ªè qua m√¥ h√¨nh n·∫øu c√≥ l·ªói hu·∫•n luy·ªán (v√≠ d·ª•: thi·∫øu th∆∞ vi·ªán)
            st.warning(f"Kh√¥ng th·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh {name}. L·ªói: {e}")


    # T√¨m m√¥ h√¨nh t·ªët nh·∫•t ƒë·ªÉ hi·ªÉn th·ªã m·∫∑c ƒë·ªãnh
    best_model_name = min(model_results, key=lambda k: model_results[k]['rmse'])
    
    feature_names = X_scaled.columns.tolist()

    return model_results, best_model_name, feature_names, scaler, df_raw

# -----------------------------------------------------------------------------------
# H√ÄM D·ª∞ ƒêO√ÅN V·ªöI INPUT TH√î (Gi·ªØ nguy√™n)
# -----------------------------------------------------------------------------------
def predict_raw_input(raw_input_dict, df_raw_full, feature_names, scaler, selected_model):
    """Th·ª±c hi·ªán d·ª± ƒëo√°n t·ª´ input th√¥ c·ªßa ng∆∞·ªùi d√πng b·∫±ng m√¥ h√¨nh ƒë√£ ch·ªçn."""
    
    df_full_history = df_raw_full.copy()
    
    input_row_series = pd.Series({
        'date': pd.to_datetime(raw_input_dict['date']),
        'Gia_Brent(USD)': raw_input_dict['Gia_Brent(USD)'],
        'Gia_WTI(USD)': raw_input_dict['Gia_WTI(USD)'],
        'USD/VND': raw_input_dict['USD/VND'],
        'loai_su_kien': raw_input_dict['loai_su_kien'],
        'ten_su_kien': np.nan, 
        'tang_giam': raw_input_dict['tang_giam'],
        'E5 RON 92-II(VND)': np.nan, 
        'RON 95-III(VND)': np.nan,   
        'Bien_loi_nhuan': np.nan 
    })
    
    df_full_history.loc[len(df_full_history)] = input_row_series
    
    X_full, _ = create_features(df_full_history, scaler=scaler, fit_scaler=False)
    
    X_predict = X_full.iloc[[-1]]
    X_predict = X_predict[feature_names] 
    
    raw_prediction = selected_model.predict(X_predict)[0]
    
    return raw_prediction, X_predict

# -----------------------------------------------------------------------------------
# PH·∫¶N CH√çNH C·ª¶A STREAMLIT APP
# -----------------------------------------------------------------------------------

# T·∫£i v√† hu·∫•n luy·ªán m√¥ h√¨nh
# (C√°c m√¥ h√¨nh kh√¥ng c√†i ƒë·∫∑t s·∫Ω tr·∫£ v·ªÅ l·ªói, nh∆∞ng ·ª©ng d·ª•ng v·∫´n ch·∫°y v·ªõi c√°c m√¥ h√¨nh kh·∫£ d·ª•ng)
model_results, best_model_name, feature_names, scaler, df_raw = load_and_train_model()

# --- Ki·ªÉm tra n·∫øu m√¥ h√¨nh t·∫£i th√†nh c√¥ng ---
if df_raw is None:
    st.stop() 

default_values_raw = df_raw.iloc[-1] 

# ----------------- Giao di·ªán Streamlit -----------------

st.set_page_config(page_title="D·ª± ƒëo√°n Gi√° XƒÉng RON 95-III", layout="wide")
st.title("‚õΩ ·ª®ng d·ª•ng D·ª± ƒëo√°n Gi√° XƒÉng RON 95-III N·ªôi ƒë·ªãa")

# 1. H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t
st.markdown("""
    <div style='background-color:#fff3cd; color:#856404; padding: 10px; border-radius: 5px;'>
        <strong>‚ö†Ô∏è H∆Ø·ªöNG D·∫™N:</strong> ƒê·ªÉ s·ª≠ d·ª•ng c√°c m√¥ h√¨nh Gradient Boosting n√¢ng cao (XGBoost, LightGBM, CatBoost), 
        b·∫°n ph·∫£i c√†i ƒë·∫∑t ch√∫ng trong m√¥i tr∆∞·ªùng c·ªßa m√¨nh:
        <br><code>pip install xgboost lightgbm catboost</code>
    </div>
    """, unsafe_allow_html=True)


# B·∫£ng so s√°nh RMSE
st.sidebar.subheader("üìä So s√°nh Hi·ªáu su·∫•t M√¥ h√¨nh (RMSE - VND)")
rmse_data = {
    'M√¥ h√¨nh': list(model_results.keys()),
    'RMSE (VND)': [f"{model_results[name]['rmse']:,.0f}" for name in model_results.keys()]
}
rmse_df = pd.DataFrame(rmse_data)
st.sidebar.dataframe(rmse_df.set_index('M√¥ h√¨nh'), use_container_width=True)

# L·ª±a ch·ªçn m√¥ h√¨nh
model_selection = st.sidebar.selectbox(
    "Ch·ªçn M√¥ h√¨nh D·ª± ƒëo√°n",
    options=list(model_results.keys()),
    index=list(model_results.keys()).index(best_model_name)
)

st.markdown(f"""
    <p style='font-size:18px;'>
    M√¥ h√¨nh ƒëang ƒë∆∞·ª£c s·ª≠ d·ª•ng: <b>{model_selection}</b>. 
    RMSE tr√™n t·∫≠p ki·ªÉm tra: <b>{model_results[model_selection]['rmse']:,.0f} VND</b>.
    </p>
    """, unsafe_allow_html=True)

st.sidebar.header("Th√¥ng tin ƒê·∫ßu v√†o D·ª± ƒëo√°n (Gi√° tr·ªã TH√î)")

# Raw Price Inputs
input_prices = {}
price_fields = [
    ('Gia_Brent(USD)', 'Gi√° Brent (USD)'),
    ('Gia_WTI(USD)', 'Gi√° WTI (USD)'),
    ('USD/VND', 'T·ª∑ gi√° USD/VND')
]

st.sidebar.subheader("I. Gi√° H√†ng h√≥a & T·ª∑ gi√°")
for feature_name, label in price_fields:
    default_val = float(default_values_raw[feature_name]) if not pd.isna(default_values_raw[feature_name]) else 70.0
    input_prices[feature_name] = st.sidebar.number_input(
        label,
        value=default_val,
        step=0.01,
        format="%.2f",
        key=f"raw_input_{feature_name}"
    )

# Event Inputs
st.sidebar.subheader("II. Th√¥ng tin S·ª± ki·ªán")

unique_events = list(EVENT_MAP.keys())
unique_events.insert(0, 'Kh√¥ng c√≥ s·ª± ki·ªán')

selected_event = st.sidebar.selectbox(
    "Lo·∫°i S·ª± ki·ªán",
    options=unique_events,
    index=0
)

sentiment = st.sidebar.radio(
    "Xu h∆∞·ªõng S·ª± ki·ªán",
    options=['None', 'TƒÉng', 'Gi·∫£m'],
    index=0,
    disabled=(selected_event == 'Kh√¥ng c√≥ s·ª± ki·ªán')
)

# Date input 
last_date = pd.to_datetime(df_raw.iloc[-1]['date'])
input_date = st.sidebar.date_input(
    "Ng√†y D·ª± ƒëo√°n",
    value=last_date + pd.Timedelta(days=1),
    min_value=last_date + pd.Timedelta(days=1),
    key="input_date"
)

# ----------------- N√∫t D·ª± ƒëo√°n -----------------

st.sidebar.markdown("---")
if st.sidebar.button("D·ª± ƒëo√°n Gi√° XƒÉng (VND)", type="primary"):
    selected_model = model_results[model_selection]['model']
    
    if selected_model is not None:
        st.header("K·∫øt qu·∫£ D·ª± ƒëo√°n")
        
        raw_input_data = {
            'date': input_date.strftime('%Y-%m-%d'),
            'Gia_Brent(USD)': input_prices['Gia_Brent(USD)'],
            'Gia_WTI(USD)': input_prices['Gia_WTI(USD)'],
            'USD/VND': input_prices['USD/VND'],
            'loai_su_kien': selected_event if selected_event != 'Kh√¥ng c√≥ s·ª± ki·ªán' else np.nan,
            'ten_su_kien': np.nan, 
            'tang_giam': sentiment if sentiment != 'None' else np.nan,
        }
        
        try:
            raw_prediction, X_predict = predict_raw_input(raw_input_data, df_raw, feature_names, scaler, selected_model)
            
            st.success(f"### D·ª± ƒëo√°n Gi√° RON 95-III (Th·ª±c t·∫ø): **{raw_prediction:,.0f} VND**")
            
            st.markdown("#### Vector ƒê·∫∑c tr∆∞ng ƒê√£ Chu·∫©n h√≥a (Scaled Features) ƒë∆∞·ª£c s·ª≠ d·ª•ng:")
            
            X_predict_T = X_predict.T
            X_predict_T.columns = ["Gi√° tr·ªã ƒê√£ Chu·∫©n h√≥a"]
            st.dataframe(X_predict_T, use_container_width=True)

        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh d·ª± ƒëo√°n: {e}")

# Footer
st.markdown("---")
st.markdown("Dashboard ƒë∆∞·ª£c t·∫°o ra ƒë·ªÉ minh h·ªça kh·∫£ nƒÉng d·ª± ƒëo√°n chu·ªói th·ªùi gian b·∫±ng c√°c m√¥ h√¨nh kh√°c nhau.")